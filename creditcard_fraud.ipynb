{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import Libraries\n"
      ],
      "metadata": {
        "id": "tZMZdvx-J0l4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "Hvr8kE9hKQ9x"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load and Explore Dataset\n"
      ],
      "metadata": {
        "id": "8nttw6n7KK8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data_path = 'creditcard.csv'  # Update this path with the actual path to your dataset\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Print the first 5 rows of the dataset\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Check the distribution of the target variable\n",
        "print(\"Distribution of target variable:\")\n",
        "print(df['Class'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH8RmeZt-bTX",
        "outputId": "6f5df104-6024-4622-de3a-90ac87592db5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the dataset:\n",
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
            "\n",
            "        V26       V27       V28  Amount  Class  \n",
            "0 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
            "1  0.125895 -0.008983  0.014724    2.69    0.0  \n",
            "2 -0.139097 -0.055353 -0.059752  378.66    0.0  \n",
            "3 -0.221929  0.062723  0.061458  123.50    0.0  \n",
            "4  0.502292  0.219422  0.215153   69.99    0.0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "Distribution of target variable:\n",
            "Class\n",
            "0.0    96919\n",
            "1.0      222\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Pre-process and Normalize the Data\n"
      ],
      "metadata": {
        "id": "N7hqwa9SKbuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values in the dataset:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Drop rows with missing values in the target variable\n",
        "df = df.dropna(subset=['Class'])\n",
        "\n",
        "# Fill or drop missing values in the features as required\n",
        "# Example: Filling missing values with the mean of the column\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYTRYQx9GFsZ",
        "outputId": "96bd9ba9-791b-4f0d-a3ea-5080fbf8d8cc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in the dataset:\n",
            "Time      0\n",
            "V1        0\n",
            "V2        0\n",
            "V3        0\n",
            "V4        0\n",
            "V5        0\n",
            "V6        0\n",
            "V7        0\n",
            "V8        0\n",
            "V9        0\n",
            "V10       0\n",
            "V11       0\n",
            "V12       0\n",
            "V13       0\n",
            "V14       0\n",
            "V15       0\n",
            "V16       0\n",
            "V17       0\n",
            "V18       0\n",
            "V19       1\n",
            "V20       1\n",
            "V21       1\n",
            "V22       1\n",
            "V23       1\n",
            "V24       1\n",
            "V25       1\n",
            "V26       1\n",
            "V27       1\n",
            "V28       1\n",
            "Amount    1\n",
            "Class     1\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Handle Class Imbalance\n"
      ],
      "metadata": {
        "id": "LN7ud8jtKi5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle class imbalance using SMOTE\n",
        "sm = SMOTE(random_state=42)\n",
        "X_res, y_res = sm.fit_resample(X_scaled, y)\n",
        "\n",
        "# Check the distribution after resampling\n",
        "print(\"Distribution after resampling:\")\n",
        "print(pd.Series(y_res).value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbfgcT_7GY-q",
        "outputId": "02ecd4a2-8f45-401a-ada4-ee4c988e37a1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution after resampling:\n",
            "Class\n",
            "0.0    96919\n",
            "1.0    96919\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Split the Dataset\n"
      ],
      "metadata": {
        "id": "fEf5-ST_Km1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "dcV8Lq7NIPrh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression\n"
      ],
      "metadata": {
        "id": "KQFZxUkwKpPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Logistic Regression model\n",
        "logreg = LogisticRegression(random_state=42)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_logreg = logreg.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ErGc1lTImy7",
        "outputId": "357abcb1-39e3-4c3a-82a6-898879d31e87"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Classifier\n"
      ],
      "metadata": {
        "id": "FpFcYT_7KsSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Random Forest model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_rf = rf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "b6vCfutzI4xc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression Evaluation\n"
      ],
      "metadata": {
        "id": "uvhPEaS-Kw4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Logistic Regression model\n",
        "print(\"Logistic Regression:\")\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_logreg))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred_logreg))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_logreg))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_logreg))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF6tulugIpg5",
        "outputId": "af9002b9-c2d3-4a61-eb8b-f9caa38f90ef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "Precision: 0.9775705913692062\n",
            "Recall: 0.9485628618693135\n",
            "F1 Score: 0.9628482972136224\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.98      0.96     19424\n",
            "         1.0       0.98      0.95      0.96     19344\n",
            "\n",
            "    accuracy                           0.96     38768\n",
            "   macro avg       0.96      0.96      0.96     38768\n",
            "weighted avg       0.96      0.96      0.96     38768\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Evaluation\n"
      ],
      "metadata": {
        "id": "X_d96qPEKzo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Random Forest model\n",
        "print(\"Random Forest:\")\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_rf))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSZEi2b9Ivdq",
        "outputId": "d2ebb96a-9d8e-4b59-bd01-583da0ae5a90"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest:\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00     19424\n",
            "         1.0       1.00      1.00      1.00     19344\n",
            "\n",
            "    accuracy                           1.00     38768\n",
            "   macro avg       1.00      1.00      1.00     38768\n",
            "weighted avg       1.00      1.00      1.00     38768\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XmoIXKYiIyF-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}